{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96375445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/AIAgents4Pharma/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add root of the repository to the path\n",
    "sys.path.append('../../..')\n",
    "\n",
    "# Import the main agent (supervisor graph)\n",
    "from aiagents4pharma.talk2scholars.agents.main_agent import get_app\n",
    "\n",
    "# Import the shared state schema\n",
    "from aiagents4pharma.talk2scholars.state.state_talk2scholars import Talk2Scholars\n",
    "\n",
    "# Suppress excessive logging from httpx\n",
    "import logging\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07d1b8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:aiagents4pharma.talk2scholars.agents.main_agent:Launching Talk2Scholars with thread_id demo_session_001\n",
      "INFO:aiagents4pharma.talk2scholars.agents.main_agent:System_prompt of Talk2Scholars: You are the Main Supervisor Agent.\n",
      "\n",
      "You have access to four tools, each represented by a sub-agent:\n",
      "\n",
      "- s2_agent: Use this to search for or recommend academic papers.\n",
      "  You can also use its `query_dataframe` tool to extract metadata from the last displayed papers.\n",
      "  This tool is not for summarization or content-level understanding ‚Äî only for metadata-level filtering or ID extraction.\n",
      "\n",
      "- zotero_agent: Use this to read from or write to the user's Zotero account.\n",
      "  This agent can also save papers to the Zotero library, but only with the user's explicit approval.\n",
      "\n",
      "- pdf_agent: Use this to perform question-and-answer tasks on downloaded, uploaded, or Zotero-based papers or PDFs.\n",
      "  This includes summarization, explanation, or answering content-based questions.\n",
      "\n",
      "- paper_download_agent: Use to download PDFs.\n",
      "\n",
      "--\n",
      "\n",
      "Tool Usage Boundaries:\n",
      "\n",
      "- Use `query_dataframe` only for metadata queries such as filtering by author, listing titles, or selecting paper IDs.\n",
      "  It is not capable of full-text summarization, content analysis, or reading PDF content.\n",
      "\n",
      "- Use `pdf_agent` to summarize or analyze the full content of any downloaded, uploaded, or Zotero-based PDF.\n",
      "\n",
      "- Never attempt to summarize or interpret paper content using `query_dataframe`. That is incorrect and will result in incomplete or misleading output.\n",
      "\n",
      "- When the user asks for a summary, explanation, or any content-based question, you must use `pdf_agent`:\n",
      "\n",
      "--\n",
      "\n",
      "Critical Paper Download Protocol:\n",
      "\n",
      "When the user requests to download paper(s), you must follow this strict 2-step protocol:\n",
      "\n",
      "1. First, always call `query_dataframe` from the `s2_agent` to extract paper IDs from the last displayed DataFrame.\n",
      "\n",
      "   - This tool must be used only to extract paper IDs.\n",
      "   - Do not pass the full user query to this tool.\n",
      "   - This step is only for retrieving the full list of available `paper_ids` and their order.\n",
      "   - If the user request refers to specific positions (like ‚Äú4th paper‚Äù), you must calculate the correct index first.\n",
      "\n",
      "2. Then, use the extracted ID(s) as input to the `paper_download_agent` to download the papers.\n",
      "\n",
      "Important format rules:\n",
      "\n",
      "- The `query_dataframe` tool always returns paper IDs with full prefixes such as `\"arxiv:...\"`, `\"doi:...\"`, or `\"pubmed:...\"`.\n",
      "- You must not modify, trim, or strip these prefixes.\n",
      "- Always pass the **exact** IDs returned from `query_dataframe` directly to the `paper_download_agent` without alteration.\n",
      "\n",
      "Do not skip step 1 under any circumstances. Even if you believe you already know the IDs or if the user repeats the request, you must still call `query_dataframe` first. Skipping this step is a critical error and will corrupt the workflow.\n",
      "\n",
      "Example reasoning:\n",
      "  - User: \"Download and summarize the fourth paper\"\n",
      "  - Step 1: Compute that the user wants the 4th paper\n",
      "  - Step 2: Call `s2_agent.query_dataframe`\n",
      "  - Step 3: Pass that ID to `paper_download_agent`\n",
      "  - Step 4: After download, use `pdf_agent` for summarization only when requested by the user\n",
      "\n",
      "Additional example:\n",
      "  - User: \"Download the first and third papers\"\n",
      "  - Step 1: Compute that the user wants paper indices 1 and 3\n",
      "  - Step 2: Call `s2_agent.query_dataframe`\n",
      "  - Step 3: Pass both IDs to `paper_download_agent`\n",
      "\n",
      "Full list example:\n",
      "  - User: \"Download all papers\", \"Download the 6th paper\",\n",
      "  - Step 1: Call `s2_agent.query_dataframe`\n",
      "  - Step 2: Pass the full list of IDs to `paper_download_agent`\n",
      "\n",
      "Always follow this sequence. It applies to every download request.\n",
      "\n",
      "--\n",
      "\n",
      "Interpreting User Requests Involving Paper Indices:\n",
      "\n",
      "When a user refers to papers using words like \"first\", \"second\", \"third\", or \"fourth\", you must interpret them as referring to numeric positions in the last displayed DataFrame.\n",
      "\n",
      "For example:\n",
      "  - \"Download the fourth paper\" ‚Üí treat as \"Download the 4th paper\"\n",
      "  - \"Download the first and third papers\" ‚Üí treat as \"Download the 1st and 3rd papers\"\n",
      "\n",
      "These word-based positions must be normalized before calling `query_dataframe`. Always compute the correct index and pass it as `row_number`.\n",
      "\n",
      "--\n",
      "\n",
      "General Coordination Instructions:\n",
      "\n",
      "Each sub-agent is specialized for a different task.\n",
      "\n",
      "You may call multiple agents, either in parallel or in sequence. After receiving output from one agent, you can call another as needed based on the user's query.\n",
      "\n",
      "Your role is to analyze the user‚Äôs request carefully, decide which sub-agent(s) to use, and coordinate their execution efficiently.\n",
      "\n",
      "Always prioritize delegation and think step-by-step before acting. Avoid answering by yourself unless explicitly necessary.\n",
      "\n",
      "INFO:aiagents4pharma.talk2scholars.agents.s2_agent:thread_id, llm_model: demo_session_001, client=<openai.resources.chat.completions.Completions object at 0x14450ed80> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x1444a12b0> root_client=<openai.OpenAI object at 0x14450d010> root_async_client=<openai.AsyncOpenAI object at 0x14450ede0> model_name='gpt-4o-mini' temperature=0.0 model_kwargs={'parallel_tool_calls': False} openai_api_key=SecretStr('**********')\n",
      "INFO:aiagents4pharma.talk2scholars.agents.s2_agent:Load Hydra configuration for Talk2Scholars S2 agent.\n",
      "INFO:aiagents4pharma.talk2scholars.agents.s2_agent:Loaded configuration for S2 agent\n",
      "INFO:aiagents4pharma.talk2scholars.agents.s2_agent:Using OpenAI model client=<openai.resources.chat.completions.Completions object at 0x14450ed80> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x1444a12b0> root_client=<openai.OpenAI object at 0x14450d010> root_async_client=<openai.AsyncOpenAI object at 0x14450ede0> model_name='gpt-4o-mini' temperature=0.0 model_kwargs={'parallel_tool_calls': False} openai_api_key=SecretStr('**********')\n",
      "INFO:aiagents4pharma.talk2scholars.agents.s2_agent:Compiled the graph with thread_id demo_session_001 and llm_model client=<openai.resources.chat.completions.Completions object at 0x14450ed80> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x1444a12b0> root_client=<openai.OpenAI object at 0x14450d010> root_async_client=<openai.AsyncOpenAI object at 0x14450ede0> model_name='gpt-4o-mini' temperature=0.0 model_kwargs={'parallel_tool_calls': False} openai_api_key=SecretStr('**********')\n",
      "INFO:aiagents4pharma.talk2scholars.agents.zotero_agent:Load Hydra configuration for Talk2Scholars Zotero agent.\n",
      "INFO:aiagents4pharma.talk2scholars.agents.zotero_agent:Loaded configuration for Zotero agent\n",
      "INFO:aiagents4pharma.talk2scholars.agents.zotero_agent:Using model client=<openai.resources.chat.completions.Completions object at 0x14450ed80> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x1444a12b0> root_client=<openai.OpenAI object at 0x14450d010> root_async_client=<openai.AsyncOpenAI object at 0x14450ede0> model_name='gpt-4o-mini' temperature=0.0 model_kwargs={'parallel_tool_calls': False} openai_api_key=SecretStr('**********')\n",
      "INFO:aiagents4pharma.talk2scholars.agents.zotero_agent:Compiled the graph with thread_id demo_session_001 and llm_model client=<openai.resources.chat.completions.Completions object at 0x14450ed80> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x1444a12b0> root_client=<openai.OpenAI object at 0x14450d010> root_async_client=<openai.AsyncOpenAI object at 0x14450ede0> model_name='gpt-4o-mini' temperature=0.0 model_kwargs={'parallel_tool_calls': False} openai_api_key=SecretStr('**********')\n",
      "INFO:aiagents4pharma.talk2scholars.agents.paper_download_agent:Loading Hydra configuration for Talk2Scholars paper download agent\n",
      "INFO:aiagents4pharma.talk2scholars.agents.paper_download_agent:Using OpenAI model client=<openai.resources.chat.completions.Completions object at 0x14450ed80> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x1444a12b0> root_client=<openai.OpenAI object at 0x14450d010> root_async_client=<openai.AsyncOpenAI object at 0x14450ede0> model_name='gpt-4o-mini' temperature=0.0 model_kwargs={'parallel_tool_calls': False} openai_api_key=SecretStr('**********')\n",
      "INFO:aiagents4pharma.talk2scholars.agents.paper_download_agent:Compiled the graph\n",
      "INFO:aiagents4pharma.talk2scholars.agents.pdf_agent:Loaded pdf_agent configuration.\n",
      "INFO:aiagents4pharma.talk2scholars.agents.pdf_agent:Using OpenAI model client=<openai.resources.chat.completions.Completions object at 0x14450ed80> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x1444a12b0> root_client=<openai.OpenAI object at 0x14450d010> root_async_client=<openai.AsyncOpenAI object at 0x14450ede0> model_name='gpt-4o-mini' temperature=0.0 model_kwargs={'parallel_tool_calls': False} openai_api_key=SecretStr('**********')\n",
      "INFO:aiagents4pharma.talk2scholars.agents.pdf_agent:Compiled the PDF agent graph.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize LLM (optional tweak depending on your config)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Create app instance (LangGraph workflow)\n",
    "app = get_app(\"demo_session_001\", llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b02712e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='How can I assist you today? If you need help with academic papers, feel free to ask!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 1085, 'total_tokens': 1106, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'finish_reason': 'stop', 'logprobs': None}, name='supervisor', id='run-8e2c6e08-715b-408c-8ef9-0197cf00c5b2-0', usage_metadata={'input_tokens': 1085, 'output_tokens': 21, 'total_tokens': 1106, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='How can I assist you today? If you need help with academic papers, feel free to ask!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 1112, 'total_tokens': 1133, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'finish_reason': 'stop', 'logprobs': None}, name='supervisor', id='run-5e03c098-dfa7-43f0-9969-f3f2032d14bd-0', usage_metadata={'input_tokens': 1112, 'output_tokens': 21, 'total_tokens': 1133, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='How can I assist you today? If you need help with academic papers, feel free to ask!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 1139, 'total_tokens': 1160, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1024}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'finish_reason': 'stop', 'logprobs': None}, name='supervisor', id='run-fef68c29-cdd2-4a29-b209-90dd5eb0fcdf-0', usage_metadata={'input_tokens': 1139, 'output_tokens': 21, 'total_tokens': 1160, 'input_token_details': {'audio': 0, 'cache_read': 1024}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='How can I assist you today? If you need help with academic papers, feel free to ask!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 1166, 'total_tokens': 1187, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'finish_reason': 'stop', 'logprobs': None}, name='supervisor', id='run-d4860d93-0b8c-4814-a46d-83daa2adbb97-0', usage_metadata={'input_tokens': 1166, 'output_tokens': 21, 'total_tokens': 1187, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})], 'last_displayed_papers': {}, 'papers': {}, 'multi_papers': {}, 'article_data': {}, 'zotero_write_approval_status': {}}\n"
     ]
    }
   ],
   "source": [
    "# Example input: download these papers\n",
    "initial_state = Talk2Scholars(\n",
    "    user_input=\"Download the following papers: 10.1074/jbc.M112.432062, 10.1038/psp.2013.64, 10.1038/s41540-024-00395-9, 10.1111/cts.12849, 10.1002/psp4.12932, 10.1371/journal.pone.0165782\",\n",
    "    thread_id=\"demo_session_001\"\n",
    ")\n",
    "\n",
    "# Run the graph\n",
    "result = app.invoke(\n",
    "    initial_state,\n",
    "    config={\"configurable\": {\"thread_id\": \"demo_session_001\"}}\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eab6a4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "# Use a more deterministic model (you can also use gpt-4 if needed)\n",
    "debug_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "\n",
    "def evaluate_agent_behavior(user_input, messages, expected_agent):\n",
    "    \"\"\"\n",
    "    Ask the LLM to evaluate whether the correct subagent was called based on the user input and agent response.\n",
    "    \"\"\"\n",
    "    chat = [\n",
    "        HumanMessage(content=f\"\"\"\n",
    "You are evaluating the behavior of a LangGraph-based multi-agent system.\n",
    "\n",
    "The user gave the input: \n",
    "\\\"\\\"\\\"{user_input}\\\"\\\"\\\"\n",
    "\n",
    "The system produced the following message history:\n",
    "{messages}\n",
    "\n",
    "Your task:\n",
    "- Identify whether the correct subagent was called. The expected subagent is: **{expected_agent}**\n",
    "- If it was not triggered or the response was vague/generic, diagnose the likely issue.\n",
    "- Suggest a rephrased user query or improvement to the supervisor system prompt.\n",
    "\n",
    "Respond in this format:\n",
    "- Was correct agent called?: [Yes/No]\n",
    "- Reasoning: ...\n",
    "- Suggested fix (if needed): ...\n",
    "\"\"\")\n",
    "    ]\n",
    "\n",
    "    return debug_llm(chat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e17ebcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/40/nbk6c34x4xb3d3xztgxyxlf00000gp/T/ipykernel_61014/823710888.py:33: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  return debug_llm(chat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Was correct agent called?: No\n",
      "- Reasoning: The response from the supervisor was vague and generic, not specifically addressing the user's request to download academic papers. It did not trigger the **paper_download_agent** that is needed for this task.\n",
      "- Suggested fix (if needed): The supervisor system prompt could be improved to explicitly mention that it can assist with downloading academic papers. A rephrased user query could be: \"Could you please download the following papers for me: 10.1074/jbc.M112.432062 and 10.1038/psp.2013.64?\"\n"
     ]
    }
   ],
   "source": [
    "# Your original input\n",
    "user_query = \"Download the following papers: 10.1074/jbc.M112.432062, 10.1038/psp.2013.64\"\n",
    "\n",
    "# Run LangGraph\n",
    "initial_state = Talk2Scholars(user_input=user_query, thread_id=\"demo_debug_01\")\n",
    "result = app.invoke(initial_state, config={\"configurable\": {\"thread_id\": \"demo_debug_01\"}})\n",
    "\n",
    "# Extract messages (cleaned)\n",
    "agent_responses = \"\\n\".join([f\"{m.name}: {m.content}\" for m in result[\"messages\"]])\n",
    "\n",
    "# Evaluate\n",
    "eval_response = evaluate_agent_behavior(user_query, agent_responses, expected_agent=\"paper_download_agent\")\n",
    "\n",
    "# Display result\n",
    "print(eval_response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99406087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def load_system_prompt(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return config[\"system_prompt\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "386a8395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "optimizer_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
    "\n",
    "def suggest_system_prompt_update(current_prompt, user_input, messages, expected_agent):\n",
    "    chat = [\n",
    "        HumanMessage(content=f\"\"\"\n",
    "You are a prompt engineering assistant.\n",
    "\n",
    "You are reviewing a LangGraph agent system. It uses a system prompt to decide which subagent to call.\n",
    "\n",
    "---\n",
    "\n",
    "Current system prompt:\n",
    "\\\"\\\"\\\"{current_prompt}\\\"\\\"\\\"\n",
    "\n",
    "User input:\n",
    "\\\"\\\"\\\"{user_input}\\\"\\\"\\\"\n",
    "\n",
    "Actual agent messages:\n",
    "\\\"\\\"\\\"{messages}\\\"\\\"\\\"\n",
    "\n",
    "The expected subagent to be triggered was: {expected_agent}\n",
    "\n",
    "---\n",
    "\n",
    "Please do the following:\n",
    "1. Briefly explain why the current prompt failed to trigger the correct agent.\n",
    "2. Then, rewrite the system prompt to improve routing for this case.\n",
    "Respond ONLY with:\n",
    "- Explanation\n",
    "- New system prompt\n",
    "\"\"\")\n",
    "    ]\n",
    "    return optimizer_llm.invoke(chat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43ff3dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_system_prompt(path, new_prompt):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "\n",
    "    config[\"system_prompt\"] = new_prompt\n",
    "\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        yaml.dump(config, f, sort_keys=False, allow_unicode=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77cf372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path exists: True\n",
      "üîç Prompt Diagnosis:\n",
      " ### Explanation\n",
      "\n",
      "The current system prompt failed to trigger the correct agent because it does not account for scenarios where the user directly provides specific paper IDs for download. The protocol described in the prompt is focused on extracting paper IDs from a DataFrame using `query_dataframe`, but it does not address cases where the user already knows and provides the IDs. This oversight leads to the system not recognizing the need to directly use the `paper_download_agent` when explicit paper IDs are given.\n",
      "\n",
      "### New System Prompt\n",
      "\n",
      "```plaintext\n",
      "You are the Main Supervisor Agent.\n",
      "\n",
      "You have access to four tools, each represented by a sub-agent:\n",
      "\n",
      "- s2_agent: Use this to search for or recommend academic papers.\n",
      "  You can also use its `query_dataframe` tool to extract metadata from the last displayed papers.\n",
      "  This tool is not for summarization or content-level understanding ‚Äî only for metadata-level filtering or ID extraction.\n",
      "\n",
      "- zotero_agent: Use this to read from or write to the user's Zotero account.\n",
      "  This agent can also save papers to the Zotero library, but only with the user's explicit approval.\n",
      "\n",
      "- pdf_agent: Use this to perform question-and-answer tasks on downloaded, uploaded, or Zotero-based papers or PDFs.\n",
      "  This includes summarization, explanation, or answering content-based questions.\n",
      "\n",
      "- paper_download_agent: Use to download PDFs.\n",
      "\n",
      "--\n",
      "\n",
      "Tool Usage Boundaries:\n",
      "\n",
      "- Use `query_dataframe` only for metadata queries such as filtering by author, listing titles, or selecting paper IDs.\n",
      "  It is not capable of full-text summarization, content analysis, or reading PDF content.\n",
      "\n",
      "- Use `pdf_agent` to summarize or analyze the full content of any downloaded, uploaded, or Zotero-based PDF.\n",
      "\n",
      "- Never attempt to summarize or interpret paper content using `query_dataframe`. That is incorrect and will result in incomplete or misleading output.\n",
      "\n",
      "- When the user asks for a summary, explanation, or any content-based question, you must use `pdf_agent`.\n",
      "\n",
      "--\n",
      "\n",
      "Critical Paper Download Protocol:\n",
      "\n",
      "When the user requests to download paper(s), follow these protocols:\n",
      "\n",
      "1. **If the user provides specific paper IDs:**\n",
      "   - Directly use the `paper_download_agent` with the provided IDs.\n",
      "   - Ensure the IDs are in the correct format with prefixes like `\"arxiv:...\"`, `\"doi:...\"`, or `\"pubmed:...\"`.\n",
      "\n",
      "2. **If the user requests papers by position or without specific IDs:**\n",
      "   - First, call `query_dataframe` from the `s2_agent` to extract paper IDs from the last displayed DataFrame.\n",
      "   - Do not pass the full user query to this tool.\n",
      "   - This step is only for retrieving the full list of available `paper_ids` and their order.\n",
      "   - If the user request refers to specific positions (like ‚Äú4th paper‚Äù), compute the correct index first.\n",
      "   - Then, use the extracted ID(s) as input to the `paper_download_agent` to download the papers.\n",
      "\n",
      "Important format rules:\n",
      "\n",
      "- The `query_dataframe` tool always returns paper IDs with full prefixes such as `\"arxiv:...\"`, `\"doi:...\"`, or `\"pubmed:...\"`.\n",
      "- You must not modify, trim, or strip these prefixes.\n",
      "- Always pass the **exact** IDs returned from `query_dataframe` directly to the `paper_download_agent` without alteration.\n",
      "\n",
      "Do not skip the necessary steps under any circumstances. Even if you believe you already know the IDs or if the user repeats the request, follow the protocol as outlined.\n",
      "\n",
      "--\n",
      "\n",
      "Interpreting User Requests Involving Paper Indices:\n",
      "\n",
      "When a user refers to papers using words like \"first\", \"second\", \"third\", or \"fourth\", interpret them as referring to numeric positions in the last displayed DataFrame.\n",
      "\n",
      "For example:\n",
      "  - \"Download the fourth paper\" ‚Üí treat as \"Download the 4th paper\"\n",
      "  - \"Download the first and third papers\" ‚Üí treat as \"Download the 1st and 3rd papers\"\n",
      "\n",
      "These word-based positions must be normalized before calling `query_dataframe`. Always compute the correct index and pass it as `row_number`.\n",
      "\n",
      "--\n",
      "\n",
      "General Coordination Instructions:\n",
      "\n",
      "Each sub-agent is specialized for a different task.\n",
      "\n",
      "You may call multiple agents, either in parallel or in sequence. After receiving output from one agent, you can call another as needed based on the user's query.\n",
      "\n",
      "Your role is to analyze the user‚Äôs request carefully, decide which sub-agent(s) to use, and coordinate their execution efficiently.\n",
      "\n",
      "Always prioritize delegation and think step-by-step before acting. Avoid answering by yourself unless explicitly necessary.\n",
      "```\n",
      "‚úÖ Updated system prompt saved.\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add root of the repository to the path\n",
    "import os\n",
    "yaml_path = \"../../../aiagents4pharma/talk2scholars/configs/agents/talk2scholars/main_agent/default.yaml\"\n",
    "print(\"Path exists:\", os.path.exists(yaml_path))\n",
    "\n",
    "user_query = \"Download the following papers: 10.1074/jbc.M112.432062, 10.1038/psp.2013.64\"\n",
    "\n",
    "# Load current prompt\n",
    "current_prompt = load_system_prompt(yaml_path)\n",
    "\n",
    "# Run the LangGraph app\n",
    "initial_state = Talk2Scholars(user_input=user_query, thread_id=\"prompt_debug\")\n",
    "result = app.invoke(initial_state, config={\"configurable\": {\"thread_id\": \"prompt_debug\"}})\n",
    "\n",
    "# Extract result messages\n",
    "messages_str = \"\\n\".join([f\"{m.name}: {m.content}\" for m in result[\"messages\"]])\n",
    "\n",
    "# Evaluate and improve prompt\n",
    "fix_response = suggest_system_prompt_update(current_prompt, user_query, messages_str, expected_agent=\"paper_download_agent\")\n",
    "print(\"üîç Prompt Diagnosis:\\n\", fix_response.content)\n",
    "\n",
    "# Extract and apply updated prompt\n",
    "import re\n",
    "\n",
    "def extract_code_block(text):\n",
    "    match = re.search(r\"```(?:plaintext)?\\n(.+?)```\", text, re.DOTALL)\n",
    "    return match.group(1).strip() if match else None\n",
    "\n",
    "new_prompt = extract_code_block(fix_response.content)\n",
    "\n",
    "if new_prompt:\n",
    "    write_system_prompt(yaml_path, new_prompt)\n",
    "    print(\" Updated system prompt saved.\")\n",
    "else:\n",
    "    print(\" Could not extract new prompt. Check LLM response formatting.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "468796b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:aiagents4pharma.talk2scholars.agents.main_agent:Launching Talk2Scholars with thread_id prompt_debug_session\n",
      "INFO:aiagents4pharma.talk2scholars.agents.main_agent:System_prompt of Talk2Scholars: You are the Main Supervisor Agent.\n",
      "\n",
      "You have access to four tools, each represented by a sub-agent:\n",
      "\n",
      "- s2_agent: Use this to search for or recommend academic papers.\n",
      "  You can also use its `query_dataframe` tool to extract metadata from the last displayed papers.\n",
      "  This tool is not for summarization or content-level understanding ‚Äî only for metadata-level filtering or ID extraction.\n",
      "\n",
      "- zotero_agent: Use this to read from or write to the user's Zotero account.\n",
      "  This agent can also save papers to the Zotero library, but only with the user's explicit approval.\n",
      "\n",
      "- pdf_agent: Use this to perform question-and-answer tasks on downloaded, uploaded, or Zotero-based papers or PDFs.\n",
      "  This includes summarization, explanation, or answering content-based questions.\n",
      "\n",
      "- paper_download_agent: Use to download PDFs.\n",
      "\n",
      "--\n",
      "\n",
      "Tool Usage Boundaries:\n",
      "\n",
      "- Use `query_dataframe` only for metadata queries such as filtering by author, listing titles, or selecting paper IDs.\n",
      "  It is not capable of full-text summarization, content analysis, or reading PDF content.\n",
      "\n",
      "- Use `pdf_agent` to summarize or analyze the full content of any downloaded, uploaded, or Zotero-based PDF.\n",
      "\n",
      "- Never attempt to summarize or interpret paper content using `query_dataframe`. That is incorrect and will result in incomplete or misleading output.\n",
      "\n",
      "- When the user asks for a summary, explanation, or any content-based question, you must use `pdf_agent`.\n",
      "\n",
      "--\n",
      "\n",
      "Critical Paper Download Protocol:\n",
      "\n",
      "When the user requests to download paper(s), follow these protocols:\n",
      "\n",
      "1. **If the user provides specific paper IDs:**\n",
      "   - Directly use the `paper_download_agent` with the provided IDs.\n",
      "   - Ensure the IDs are in the correct format with prefixes like `\"arxiv:...\"`, `\"doi:...\"`, or `\"pubmed:...\"`.\n",
      "\n",
      "2. **If the user requests papers by position or without specific IDs:**\n",
      "   - First, call `query_dataframe` from the `s2_agent` to extract paper IDs from the last displayed DataFrame.\n",
      "   - Do not pass the full user query to this tool.\n",
      "   - This step is only for retrieving the full list of available `paper_ids` and their order.\n",
      "   - If the user request refers to specific positions (like ‚Äú4th paper‚Äù), compute the correct index first.\n",
      "   - Then, use the extracted ID(s) as input to the `paper_download_agent` to download the papers.\n",
      "\n",
      "Important format rules:\n",
      "\n",
      "- The `query_dataframe` tool always returns paper IDs with full prefixes such as `\"arxiv:...\"`, `\"doi:...\"`, or `\"pubmed:...\"`.\n",
      "- You must not modify, trim, or strip these prefixes.\n",
      "- Always pass the **exact** IDs returned from `query_dataframe` directly to the `paper_download_agent` without alteration.\n",
      "\n",
      "Do not skip the necessary steps under any circumstances. Even if you believe you already know the IDs or if the user repeats the request, follow the protocol as outlined.\n",
      "\n",
      "--\n",
      "\n",
      "Interpreting User Requests Involving Paper Indices:\n",
      "\n",
      "When a user refers to papers using words like \"first\", \"second\", \"third\", or \"fourth\", interpret them as referring to numeric positions in the last displayed DataFrame.\n",
      "\n",
      "For example:\n",
      "  - \"Download the fourth paper\" ‚Üí treat as \"Download the 4th paper\"\n",
      "  - \"Download the first and third papers\" ‚Üí treat as \"Download the 1st and 3rd papers\"\n",
      "\n",
      "These word-based positions must be normalized before calling `query_dataframe`. Always compute the correct index and pass it as `row_number`.\n",
      "\n",
      "--\n",
      "\n",
      "General Coordination Instructions:\n",
      "\n",
      "Each sub-agent is specialized for a different task.\n",
      "\n",
      "You may call multiple agents, either in parallel or in sequence. After receiving output from one agent, you can call another as needed based on the user's query.\n",
      "\n",
      "Your role is to analyze the user‚Äôs request carefully, decide which sub-agent(s) to use, and coordinate their execution efficiently.\n",
      "\n",
      "Always prioritize delegation and think step-by-step before acting. Avoid answering by yourself unless explicitly necessary.\n",
      "INFO:aiagents4pharma.talk2scholars.agents.s2_agent:thread_id, llm_model: prompt_debug_session, client=<openai.resources.chat.completions.Completions object at 0x15c73e480> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x15c73f710> root_client=<openai.OpenAI object at 0x1454f4800> root_async_client=<openai.AsyncOpenAI object at 0x15c73e2d0> model_name='gpt-4o-mini' temperature=0.0 model_kwargs={'parallel_tool_calls': False} openai_api_key=SecretStr('**********')\n",
      "INFO:aiagents4pharma.talk2scholars.agents.s2_agent:Load Hydra configuration for Talk2Scholars S2 agent.\n",
      "INFO:aiagents4pharma.talk2scholars.agents.s2_agent:Loaded configuration for S2 agent\n",
      "INFO:aiagents4pharma.talk2scholars.agents.s2_agent:Using OpenAI model client=<openai.resources.chat.completions.Completions object at 0x15c73e480> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x15c73f710> root_client=<openai.OpenAI object at 0x1454f4800> root_async_client=<openai.AsyncOpenAI object at 0x15c73e2d0> model_name='gpt-4o-mini' temperature=0.0 model_kwargs={'parallel_tool_calls': False} openai_api_key=SecretStr('**********')\n",
      "INFO:aiagents4pharma.talk2scholars.agents.s2_agent:Compiled the graph with thread_id prompt_debug_session and llm_model client=<openai.resources.chat.completions.Completions object at 0x15c73e480> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x15c73f710> root_client=<openai.OpenAI object at 0x1454f4800> root_async_client=<openai.AsyncOpenAI object at 0x15c73e2d0> model_name='gpt-4o-mini' temperature=0.0 model_kwargs={'parallel_tool_calls': False} openai_api_key=SecretStr('**********')\n",
      "INFO:aiagents4pharma.talk2scholars.agents.zotero_agent:Load Hydra configuration for Talk2Scholars Zotero agent.\n",
      "INFO:aiagents4pharma.talk2scholars.agents.zotero_agent:Loaded configuration for Zotero agent\n",
      "INFO:aiagents4pharma.talk2scholars.agents.zotero_agent:Using model client=<openai.resources.chat.completions.Completions object at 0x15c73e480> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x15c73f710> root_client=<openai.OpenAI object at 0x1454f4800> root_async_client=<openai.AsyncOpenAI object at 0x15c73e2d0> model_name='gpt-4o-mini' temperature=0.0 model_kwargs={'parallel_tool_calls': False} openai_api_key=SecretStr('**********')\n",
      "INFO:aiagents4pharma.talk2scholars.agents.zotero_agent:Compiled the graph with thread_id prompt_debug_session and llm_model client=<openai.resources.chat.completions.Completions object at 0x15c73e480> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x15c73f710> root_client=<openai.OpenAI object at 0x1454f4800> root_async_client=<openai.AsyncOpenAI object at 0x15c73e2d0> model_name='gpt-4o-mini' temperature=0.0 model_kwargs={'parallel_tool_calls': False} openai_api_key=SecretStr('**********')\n",
      "INFO:aiagents4pharma.talk2scholars.agents.paper_download_agent:Loading Hydra configuration for Talk2Scholars paper download agent\n",
      "INFO:aiagents4pharma.talk2scholars.agents.paper_download_agent:Using OpenAI model client=<openai.resources.chat.completions.Completions object at 0x15c73e480> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x15c73f710> root_client=<openai.OpenAI object at 0x1454f4800> root_async_client=<openai.AsyncOpenAI object at 0x15c73e2d0> model_name='gpt-4o-mini' temperature=0.0 model_kwargs={'parallel_tool_calls': False} openai_api_key=SecretStr('**********')\n",
      "INFO:aiagents4pharma.talk2scholars.agents.paper_download_agent:Compiled the graph\n",
      "INFO:aiagents4pharma.talk2scholars.agents.pdf_agent:Loaded pdf_agent configuration.\n",
      "INFO:aiagents4pharma.talk2scholars.agents.pdf_agent:Using OpenAI model client=<openai.resources.chat.completions.Completions object at 0x15c73e480> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x15c73f710> root_client=<openai.OpenAI object at 0x1454f4800> root_async_client=<openai.AsyncOpenAI object at 0x15c73e2d0> model_name='gpt-4o-mini' temperature=0.0 model_kwargs={'parallel_tool_calls': False} openai_api_key=SecretStr('**********')\n",
      "INFO:aiagents4pharma.talk2scholars.agents.pdf_agent:Compiled the PDF agent graph.\n"
     ]
    }
   ],
   "source": [
    "test_cases = [\n",
    "    (\"Download paper 10.1038/s41540-024-00395-9\", \"paper_download_agent\"),\n",
    "    (\"Summarize the uploaded PDF\", \"pdf_agent\"),\n",
    "    (\"Search for papers on LLMs and neuroscience\", \"s2_agent\"),\n",
    "    (\"Add this article to Zotero\", \"zotero_agent\"),\n",
    "]\n",
    "app = get_app(\"prompt_debug_session\", llm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIAgents4Pharma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
